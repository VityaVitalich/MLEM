{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append('../../../')\n",
    "\n",
    "from configs.data_configs.rosbank import data_configs\n",
    "from configs.model_configs.gen.rosbank import model_configs\n",
    "from src.data_load.dataloader import create_data_loaders, create_test_loader\n",
    "\n",
    "from src.models.model_utils import NumericalFeatureProjector, EmbeddingPredictor\n",
    "import src.models.preprocessors as prp\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from einops import repeat\n",
    "\n",
    "from src.models.tpp_ddpm import TPPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionEmbedding(nn.Module):\n",
    "    def __init__(self, embed_size, max_steps=500):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\n",
    "            \"embedding\", self._build_embedding(embed_size, max_steps), persistent=False\n",
    "        )\n",
    "        self.projection1 = nn.Linear(embed_size * 2, embed_size)\n",
    "        self.projection2 = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "    def forward(self, diffusion_step):\n",
    "        x = self.embedding[diffusion_step]\n",
    "        x = self.projection1(x)\n",
    "        x = F.silu(x)\n",
    "        x = self.projection2(x)\n",
    "        x = F.silu(x)\n",
    "        return x\n",
    "\n",
    "    def _build_embedding(self, dim, max_steps):\n",
    "        steps = torch.arange(max_steps).unsqueeze(1)  # [T,1]\n",
    "        dims = torch.arange(dim).unsqueeze(0)  # [1,dim]\n",
    "        table = steps * 10.0 ** (dims * 4.0 / dim)  # [T,dim]\n",
    "        table = torch.cat([torch.sin(table), torch.cos(table)], dim=1)\n",
    "        return table\n",
    "    \n",
    "class TrigonoTimeEmbedding(nn.Module):\n",
    "    def __init__(self, embed_size, **kwargs):\n",
    "        super().__init__()\n",
    "        assert embed_size%2 == 0 \n",
    "        \n",
    "        self.Wt = nn.Linear(1, embed_size // 2, bias=False)\n",
    "\n",
    "    def forward(self, interval):\n",
    "        phi = self.Wt(interval.unsqueeze(-1))\n",
    "        pe_sin = torch.sin(phi)\n",
    "        pe_cos = torch.cos(phi)\n",
    "        pe = torch.cat([pe_sin, pe_cos], dim=-1)\n",
    "        return pe\n",
    "\n",
    "class DenoiseNet(nn.Module):\n",
    "    def __init__(self, embed_size, layer_num, diff_steps, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.embed_size=embed_size\n",
    "        \n",
    "        self.time_emb = TrigonoTimeEmbedding(embed_size=embed_size)\n",
    "        self.h_emb = nn.Linear(embed_size, embed_size)\n",
    "        self.feed_forward = nn.ModuleList([nn.Linear(embed_size, embed_size) for i in range(layer_num)])\n",
    "        self.to_time = nn.Linear(embed_size, 1)\n",
    "        self.activation = nn.GELU()\n",
    "        self.diffusion_time_emb = DiffusionEmbedding(embed_size=embed_size, max_steps=diff_steps + 1)\n",
    "        \n",
    "    # def forward(self, x, t, cond):\n",
    "    #     time_embedding = self.time_emb(x)/np.sqrt(self.embed_size) # removed x.squeeze(dim=-1\n",
    "    #     cond = self.h_emb(cond)\n",
    "    #     print(time_embedding.size())\n",
    "    #     b, l, d = time_embedding.shape # l = 1 due to reshape\n",
    "       \n",
    "    #     diff_time_embedding = self.diffusion_time_emb(t)\\\n",
    "    #                           .reshape(b, 1, self.embed_size)\\\n",
    "    #                           .expand_as(time_embedding)\n",
    "        \n",
    "    #     y = time_embedding + diff_time_embedding + cond\n",
    "    #     for layer in self.feed_forward:\n",
    "    #         y = layer(y)\n",
    "    #         y = self.activation(y) + time_embedding + diff_time_embedding + cond\n",
    "    #     return self.to_time(y)\n",
    "\n",
    "    def forward(self, x, t, cond):\n",
    "        time_embedding = self.time_emb(x.squeeze(dim=-1))/np.sqrt(self.embed_size)\n",
    "        cond = self.h_emb(cond)\n",
    "        b, *_ = time_embedding.shape\n",
    "        \n",
    "        diff_time_embedding = self.diffusion_time_emb(t)\\\n",
    "                              .reshape(b, *(1,) * (len(time_embedding.shape) - 2), self.embed_size)\\\n",
    "                              .expand_as(time_embedding)\n",
    "        \n",
    "        y = time_embedding + diff_time_embedding + cond\n",
    "        for layer in self.feed_forward:\n",
    "            y = layer(y)\n",
    "            y = self.activation(y) + time_embedding + diff_time_embedding + cond\n",
    "        return self.to_time(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from inspect import isfunction\n",
    "\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def default(val, d):\n",
    "    if val is not None:\n",
    "        return val\n",
    "    return d() if isfunction(d) else d\n",
    "\n",
    "\n",
    "def extract(a, t, x_shape):\n",
    "    b, *_ = t.shape\n",
    "    out = a.gather(-1, t)\n",
    "    return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
    "\n",
    "\n",
    "def noise_like(shape, device, repeat=False):\n",
    "    repeat_noise = lambda: torch.randn((1, *shape[1:]), device=device).repeat(\n",
    "        shape[0], *((1,) * (len(shape) - 1))\n",
    "    )\n",
    "    noise = lambda: torch.randn(shape, device=device)\n",
    "    return repeat_noise() if repeat else noise()\n",
    "\n",
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    \"\"\"\n",
    "    cosine schedule\n",
    "    as proposed in https://openreview.net/forum?id=-NEXDKk8gZ\n",
    "    \"\"\"\n",
    "    steps = timesteps + 1\n",
    "    x = np.linspace(0, steps, steps)\n",
    "    alphas_cumprod = np.cos(((x / steps) + s) / (1 + s) * np.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return np.clip(betas, a_min=0, a_max=0.999)\n",
    "\n",
    "class GaussianDiffusion(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        denoise_fn,\n",
    "        beta_end=0.1,\n",
    "        diff_steps=1000,\n",
    "        loss_type=\"l2\",\n",
    "        betas=None,\n",
    "        beta_schedule=\"linear\",\n",
    "        *args, **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.denoise_fn = denoise_fn\n",
    "        self.input_size = 1\n",
    "        self.__scale = None\n",
    "\n",
    "        if betas is not None:\n",
    "            betas = (\n",
    "                betas.detach().cpu().numpy()\n",
    "                if isinstance(betas, torch.Tensor)\n",
    "                else betas\n",
    "            )\n",
    "        else:\n",
    "            if beta_schedule == \"linear\":\n",
    "                betas = np.linspace(1e-4, beta_end, diff_steps)\n",
    "            elif beta_schedule == \"quad\":\n",
    "                betas = np.linspace(1e-4 ** 0.5, beta_end ** 0.5, diff_steps) ** 2\n",
    "            elif beta_schedule == \"const\":\n",
    "                betas = beta_end * np.ones(diff_steps)\n",
    "            elif beta_schedule == \"jsd\":  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n",
    "                betas = 1.0 / np.linspace(diff_steps, 1, diff_steps)\n",
    "            elif beta_schedule == \"sigmoid\":\n",
    "                betas = np.linspace(-6, 6, diff_steps)\n",
    "                betas = (beta_end - 1e-4) / (np.exp(-betas) + 1) + 1e-4\n",
    "            elif beta_schedule == \"cosine\":\n",
    "                betas = cosine_beta_schedule(diff_steps)\n",
    "            else:\n",
    "                raise NotImplementedError(beta_schedule)\n",
    "\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "        alphas_cumprod_prev = np.append(1.0, alphas_cumprod[:-1])\n",
    "\n",
    "        (timesteps,) = betas.shape\n",
    "        self.num_timesteps = int(timesteps)\n",
    "        self.loss_type = loss_type\n",
    "\n",
    "        to_torch = partial(torch.tensor, dtype=torch.float32)\n",
    "\n",
    "        self.register_buffer(\"betas\", to_torch(betas))\n",
    "        self.register_buffer(\"alphas_cumprod\", to_torch(alphas_cumprod))\n",
    "        self.register_buffer(\"alphas_cumprod_prev\", to_torch(alphas_cumprod_prev))\n",
    "\n",
    "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "        self.register_buffer(\"sqrt_alphas_cumprod\", to_torch(np.sqrt(alphas_cumprod)))\n",
    "        self.register_buffer(\n",
    "            \"sqrt_one_minus_alphas_cumprod\", to_torch(np.sqrt(1.0 - alphas_cumprod))\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"log_one_minus_alphas_cumprod\", to_torch(np.log(1.0 - alphas_cumprod))\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"sqrt_recip_alphas_cumprod\", to_torch(np.sqrt(1.0 / alphas_cumprod))\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"sqrt_recipm1_alphas_cumprod\", to_torch(np.sqrt(1.0 / alphas_cumprod - 1))\n",
    "        )\n",
    "\n",
    "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        posterior_variance = (\n",
    "            betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
    "        )\n",
    "        # above: equal to 1. / (1. / (1. - alpha_cumprod_tm1) + alpha_t / beta_t)\n",
    "        self.register_buffer(\"posterior_variance\", to_torch(posterior_variance))\n",
    "        # below: log calculation clipped because the posterior variance is 0 at the beginning of the diffusion chain\n",
    "        self.register_buffer(\n",
    "            \"posterior_log_variance_clipped\",\n",
    "            to_torch(np.log(np.maximum(posterior_variance, 1e-20))),\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"posterior_mean_coef1\",\n",
    "            to_torch(betas * np.sqrt(alphas_cumprod_prev) / (1.0 - alphas_cumprod)),\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"posterior_mean_coef2\",\n",
    "            to_torch(\n",
    "                (1.0 - alphas_cumprod_prev) * np.sqrt(alphas) / (1.0 - alphas_cumprod)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def scale(self):\n",
    "        return self.__scale\n",
    "\n",
    "    @scale.setter\n",
    "    def scale(self, scale):\n",
    "        self.__scale = scale\n",
    "\n",
    "    def q_mean_variance(self, x_start, t):\n",
    "        mean = extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start\n",
    "        variance = extract(1.0 - self.alphas_cumprod, t, x_start.shape)\n",
    "        log_variance = extract(self.log_one_minus_alphas_cumprod, t, x_start.shape)\n",
    "        return mean, variance, log_variance\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        return (\n",
    "            extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t\n",
    "            - extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n",
    "        )\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t):\n",
    "        posterior_mean = (\n",
    "            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start\n",
    "            + extract(self.posterior_mean_coef2, t, x_t.shape) * x_t\n",
    "        )\n",
    "        posterior_variance = extract(self.posterior_variance, t, x_t.shape)\n",
    "        posterior_log_variance_clipped = extract(\n",
    "            self.posterior_log_variance_clipped, t, x_t.shape\n",
    "        )\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "\n",
    "    def p_mean_variance(self, x, cond, t, clip_denoised: bool):\n",
    "        x_recon = self.predict_start_from_noise(\n",
    "            x, t=t, noise=self.denoise_fn(x, t, cond=cond)\n",
    "        )\n",
    "\n",
    "        if clip_denoised:\n",
    "            x_recon.clamp_(-1.0, 1.0)\n",
    "\n",
    "        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(\n",
    "            x_start=x_recon, x_t=x, t=t\n",
    "        )\n",
    "        return model_mean, posterior_variance, posterior_log_variance\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, x, cond, t, clip_denoised=False, repeat_noise=False):\n",
    "        b, *_, device = *x.shape, x.device\n",
    "        model_mean, _, model_log_variance = self.p_mean_variance(\n",
    "            x=x, cond=cond, t=t, clip_denoised=clip_denoised\n",
    "        )\n",
    "        noise = noise_like(x.shape, device, repeat_noise)\n",
    "        # no noise when t == 0\n",
    "        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))\n",
    "        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise\n",
    "\n",
    "    def get_param(self, x, cond, t, clip_denoised=False):\n",
    "        b, *_, device = *x.shape, x.device\n",
    "        model_mean, _, model_log_variance = self.p_mean_variance(\n",
    "            x=x, cond=cond, t=torch.full((b,), t, device=device, dtype=torch.long), clip_denoised=clip_denoised\n",
    "        )\n",
    "        \n",
    "        return model_mean, (0.5 * model_log_variance).exp()\n",
    "    \n",
    "    def conditional_nll_param(self, shape, cond):\n",
    "        device = self.betas.device\n",
    "\n",
    "        b = shape[0]\n",
    "        img = torch.randn(shape, device=device)\n",
    "\n",
    "        for i in reversed(range(1, self.num_timesteps)):\n",
    "            img = self.p_sample(\n",
    "                img, cond, torch.full((b,), i, device=device, dtype=torch.long)\n",
    "            )\n",
    "        gaussian_mu, gaussian_std = self.get_param(img, cond, t=1)\n",
    "        return gaussian_mu, gaussian_std\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def p_sample_loop(self, shape, cond):\n",
    "        device = self.betas.device\n",
    "\n",
    "        b = shape[0]\n",
    "        img = torch.randn(shape, device=device)\n",
    "        # emb = []\n",
    "        for i in reversed(range(0, self.num_timesteps)):\n",
    "            img = self.p_sample(\n",
    "                img, cond, torch.full((b,), i, device=device, dtype=torch.long)\n",
    "            )\n",
    "            \n",
    "            #emb.append(img)\n",
    "        # np.save('diffusion_dynamics', torch.stack(emb, dim=0).cpu().numpy())\n",
    "        return img\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, sample_shape=torch.Size(), cond=None):\n",
    "        # if cond is not None:\n",
    "        #     shape = cond.shape[:-1] + (self.input_size,)\n",
    "        # else:\n",
    "        shape = sample_shape\n",
    "        x_hat = self.p_sample_loop(shape, cond) \n",
    "\n",
    "        if self.scale is not None:\n",
    "            x_hat *= self.scale\n",
    "        return x_hat\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def interpolate(self, x1, x2, t=None, lam=0.5):\n",
    "        b, *_, device = *x1.shape, x1.device\n",
    "        t = default(t, self.num_timesteps - 1)\n",
    "\n",
    "        assert x1.shape == x2.shape\n",
    "\n",
    "        t_batched = torch.stack([torch.tensor(t, device=device)] * b)\n",
    "        xt1, xt2 = map(lambda x: self.q_sample(x, t=t_batched), (x1, x2))\n",
    "\n",
    "        img = (1 - lam) * xt1 + lam * xt2\n",
    "        for i in reversed(range(0, t)):\n",
    "            img = self.p_sample(\n",
    "                img, torch.full((b,), i, device=device, dtype=torch.long)\n",
    "            )\n",
    "\n",
    "        return img\n",
    "\n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "\n",
    "        return (\n",
    "            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start\n",
    "            + extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise\n",
    "        )\n",
    "\n",
    "    def p_losses(self, x_start, cond, t, mask=None, noise=None):\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "\n",
    "        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)\n",
    "        x_recon = self.denoise_fn(x_noisy, t, cond=cond)\n",
    "\n",
    "        if mask is not None:\n",
    "            x_noisy = x_noisy * mask\n",
    "            x_recon = x_recon * mask\n",
    "        \n",
    "        if self.loss_type == \"l1\":\n",
    "            loss = torch.abs(x_recon - noise).sum()\n",
    "        elif self.loss_type == \"l2\":\n",
    "            loss = torch.square(x_recon - noise).sum()\n",
    "        # elif self.loss_type == \"huber\":\n",
    "        #     loss = F.smooth_l1_loss(x_recon, noise)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def log_prob(self, x, cond, mask=None, *args, **kwargs):\n",
    "        if self.scale is not None:\n",
    "            x /= self.scale\n",
    "\n",
    "        # T = length of sequence\n",
    "        B, T, D = cond.shape\n",
    "\n",
    "        time = torch.randint(0, self.num_timesteps, (B * T,), device=x.device).long()\n",
    "        loss = self.p_losses(\n",
    "            x.reshape(B * T, -1), cond.reshape(B * T, -1), time)#, mask.reshape(B * T, -1, 1), *args, **kwargs\n",
    "      #  )\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TPPD(nn.Module):\n",
    "    def __init__(self, model_conf, data_conf):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model_conf = model_conf\n",
    "        self.data_conf = data_conf\n",
    "\n",
    "        ### PROCESSORS ###\n",
    "        self.processor = prp.FeatureProcessor(\n",
    "            model_conf=model_conf, data_conf=data_conf\n",
    "        )\n",
    "        self.time_encoder = prp.TimeEncoder(\n",
    "            model_conf=self.model_conf, data_conf=self.data_conf\n",
    "        )\n",
    "\n",
    "        ### INPUT SIZE ###\n",
    "        all_emb_size = self.model_conf.features_emb_dim * len(\n",
    "            self.data_conf.features.embeddings\n",
    "        )\n",
    "\n",
    "        self.all_numeric_size = (\n",
    "            len(self.data_conf.features.numeric_values)\n",
    "            * self.model_conf.numeric_emb_size\n",
    "        )\n",
    "\n",
    "        self.input_dim = (\n",
    "            all_emb_size + self.all_numeric_size + self.model_conf.use_deltas\n",
    "        )\n",
    "        assert self.model_conf.time_embedding == 0\n",
    "        assert self.model_conf.use_deltas == True\n",
    "\n",
    "        self.history_encoder = nn.GRU(\n",
    "            input_size=self.input_dim,\n",
    "            hidden_size=self.model_conf.tppvae.hidden_rnn,\n",
    "            num_layers=self.model_conf.tppvae.num_layers_enc,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.h0 = nn.Parameter(torch.rand(self.model_conf.tppvae.hidden_rnn))\n",
    "\n",
    "        ### Decoder ###\n",
    "        self.denoise_net = DenoiseNet(self.model_conf.tppvae.hidden_rnn, layer_num=self.model_conf.tppvae.joint_layer_num, diff_steps=100)\n",
    "        self.diffusion = GaussianDiffusion(self.denoise_net, diff_steps=100)\n",
    "        # predict embedding from history\n",
    "        self.embedding_head = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                self.model_conf.tppvae.hidden_rnn, self.model_conf.tppvae.hidden_rnn\n",
    "            ),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.model_conf.tppvae.hidden_rnn, self.input_dim),\n",
    "        )\n",
    "\n",
    "        # Predictors\n",
    "        self.embedding_predictor = EmbeddingPredictor(\n",
    "            model_conf=self.model_conf, data_conf=self.data_conf\n",
    "        )\n",
    "        self.numeric_projector = NumericalFeatureProjector(\n",
    "            model_conf=self.model_conf, data_conf=self.data_conf\n",
    "        )\n",
    "        self.mse_fn = torch.nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "    def numerical_loss(self, output):\n",
    "        # MSE\n",
    "        total_mse_loss = 0\n",
    "        for key, values in output[\"gt\"][\"input_batch\"].payload.items():\n",
    "            if key in self.processor.numeric_names:\n",
    "                gt_val = values.float()\n",
    "                pred_val = output[\"pred\"][key].squeeze(-1)\n",
    "\n",
    "                mse_loss = self.mse_fn(\n",
    "                    gt_val,\n",
    "                    pred_val,\n",
    "                )\n",
    "                mask = gt_val != 0\n",
    "                masked_mse = mse_loss * mask\n",
    "                total_mse_loss += (\n",
    "                    masked_mse.sum(dim=1)  # / (mask != 0).sum(dim=1)\n",
    "                ).mean()\n",
    "\n",
    "        return total_mse_loss\n",
    "\n",
    "    def delta_diff_loss(self, output):\n",
    "        # DELTA MSE\n",
    "        \n",
    "        gt_delta = output[\"gt\"][\"time_steps\"].diff(1)\n",
    "        h = output['history_emb'][:,:-1,:]\n",
    "        log_prob = self.diffusion.log_prob(gt_delta, cond=h)\n",
    "\n",
    "\n",
    "        return log_prob\n",
    "\n",
    "    def loss(self, output, ground_truth):\n",
    "        \"\"\"\n",
    "        output: Dict that is outputed from forward method\n",
    "        \"\"\"\n",
    "        ### MSE ###\n",
    "        total_mse_loss = self.numerical_loss(output)\n",
    "        delta_diff_loss = self.delta_diff_loss(output)\n",
    "\n",
    "        ### CROSS ENTROPY ###\n",
    "        cross_entropy_losses = self.embedding_predictor.loss(\n",
    "            output[\"pred\"], output[\"gt\"][\"input_batch\"]\n",
    "        )\n",
    "        total_ce_loss = torch.sum(\n",
    "            torch.cat([value.unsqueeze(0) for _, value in cross_entropy_losses.items()])\n",
    "        )\n",
    "\n",
    "        losses_dict = {\n",
    "            \"total_mse_loss\": total_mse_loss,\n",
    "            \"total_CE_loss\": total_ce_loss,\n",
    "            \"delta_loss\": self.model_conf.delta_weight * delta_diff_loss,\n",
    "        }\n",
    "        losses_dict.update(cross_entropy_losses)\n",
    "\n",
    "        total_loss = (\n",
    "            self.model_conf.mse_weight * losses_dict[\"total_mse_loss\"]\n",
    "            + self.model_conf.CE_weight * total_ce_loss\n",
    "            + self.model_conf.delta_weight * delta_diff_loss\n",
    "        )\n",
    "        losses_dict[\"total_loss\"] = total_loss\n",
    "\n",
    "        return losses_dict\n",
    "\n",
    "    def forward(self, padded_batch, need_delta=False):\n",
    "        x, time_steps = self.processor(padded_batch)\n",
    "        x = self.time_encoder(x, time_steps)\n",
    "\n",
    "        history_emb = self.encode(x)\n",
    "\n",
    "        pred = self.decode(history_emb, need_delta)\n",
    "\n",
    "        lens = padded_batch.seq_lens - 1\n",
    "        global_hidden = history_emb[:, lens, :].diagonal().T\n",
    "\n",
    "        gt = {\"input_batch\": padded_batch, \"time_steps\": time_steps}\n",
    "\n",
    "        res_dict = {\n",
    "            \"gt\": gt,\n",
    "            \"pred\": pred,\n",
    "            \"latent\": global_hidden,\n",
    "            \"history_emb\": history_emb,\n",
    "        }\n",
    "        return res_dict\n",
    "\n",
    "    def encode(self, x):\n",
    "        bs, seq_len, dim = x.size()\n",
    "        history_emb, _ = self.history_encoder(x)\n",
    "        history_emb = torch.cat(\n",
    "            [repeat(self.h0, \"D -> B L D\", B=bs, L=1), history_emb], dim=1\n",
    "        )[:, :-1, :] # shift history emb\n",
    "\n",
    "        return history_emb\n",
    "\n",
    "    def decode(self, h, need_delta=False):\n",
    "        # out = self.decoder_net_joint(self.decoder_net_h(h) + self.decoder_z_emb(z))\n",
    "        # pred_delta = self.delta_head(out)\n",
    "        out = self.embedding_head(h)\n",
    "\n",
    "        pred = self.embedding_predictor(out)\n",
    "        pred.update(self.numeric_projector(out))\n",
    "        \n",
    "        # need in reconstruction measure\n",
    "        if need_delta:\n",
    "            bs, l, d = h.size()\n",
    "            pred_delta = self.diffusion.sample((bs, l, 1), cond=h)\n",
    "            pred[\"delta\"] = pred_delta.squeeze(-1)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def generate(self, padded_batch, lens):\n",
    "        bs, l = padded_batch.payload[\"event_time\"].size()\n",
    "\n",
    "        initial_state = repeat(self.h0, \"D -> BS D\", BS=bs)\n",
    "        # z = torch.randn(bs, self.model_conf.tppvae.hidden_rnn).to(\n",
    "        #     self.model_conf.device\n",
    "        # )\n",
    "        out = self.embedding_head(\n",
    "            initial_state\n",
    "        )\n",
    "        pred_delta = self.diffusion.sample((bs, 1), cond=initial_state).squeeze(-1)\n",
    "      #  out = self.embedding_head(initial_state)\n",
    "        out[:, -1] = pred_delta\n",
    "\n",
    "        gen_x = torch.zeros(bs, lens, self.input_dim, device='cpu')\n",
    "        gen_x[:, 0, :] = out\n",
    "        for i in range(1, lens):\n",
    "            history_emb, _ = self.history_encoder(gen_x)\n",
    "            history_emb = history_emb[:, i - 1, :]\n",
    "            # z = torch.randn(bs, self.model_conf.tppvae.hidden_rnn).to(\n",
    "            #     self.model_conf.device\n",
    "            # )\n",
    "\n",
    "            # out = self.decoder_net_joint(\n",
    "            #     self.decoder_net_h(history_emb) + self.decoder_z_emb(z)\n",
    "            # )\n",
    "            out = self.embedding_head(\n",
    "                history_emb\n",
    "            )\n",
    "            pred_delta = self.diffusion.sample((bs, 1), cond=history_emb).squeeze(-1)\n",
    "            out[:, -1] = pred_delta\n",
    "\n",
    "            gen_x[:, i, :] = out\n",
    "\n",
    "        pred = self.embedding_predictor(gen_x)\n",
    "        pred.update(self.numeric_projector(gen_x))\n",
    "        pred[\"delta\"] = gen_x[:, :, -1]\n",
    "        return {\"pred\": pred}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_conf = data_configs()\n",
    "model_conf = model_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tppd = TPPD(model_conf=model_conf, data_conf=data_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes: train 8467, val 946, test 0\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = create_data_loaders(data_conf, supervised=False)\n",
    "for batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tppd(batch[0], need_delta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 200])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['pred']['delta'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_mse_loss': tensor(4124.6455, grad_fn=<AddBackward0>),\n",
       " 'total_CE_loss': tensor(854.2460, grad_fn=<SumBackward0>),\n",
       " 'delta_loss': tensor(27326.4727, grad_fn=<MulBackward0>),\n",
       " 'channel_type': tensor(133.6876, grad_fn=<MeanBackward0>),\n",
       " 'currency': tensor(132.9385, grad_fn=<MeanBackward0>),\n",
       " 'mcc': tensor(382.1283, grad_fn=<MeanBackward0>),\n",
       " 'trx_category': tensor(205.4916, grad_fn=<MeanBackward0>),\n",
       " 'total_loss': tensor(32305.3633, grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tppd.loss(out, batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TPPD(\n",
       "  (processor): FeatureProcessor(\n",
       "    (embed_layers): ModuleDict(\n",
       "      (channel_type): Embedding(5, 16)\n",
       "      (currency): Embedding(5, 16)\n",
       "      (mcc): Embedding(100, 16)\n",
       "      (trx_category): Embedding(12, 16)\n",
       "    )\n",
       "    (numeric_processor): ModuleDict(\n",
       "      (amount): Linear(in_features=1, out_features=16, bias=True)\n",
       "    )\n",
       "    (numeric_norms): ModuleDict(\n",
       "      (amount): RBatchNormWithLens(\n",
       "        (bn): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (time_encoder): TimeEncoder()\n",
       "  (history_encoder): GRU(81, 64, batch_first=True)\n",
       "  (denoise_net): DenoiseNet(\n",
       "    (time_emb): TrigonoTimeEmbedding(\n",
       "      (Wt): Linear(in_features=1, out_features=32, bias=False)\n",
       "    )\n",
       "    (h_emb): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (feed_forward): ModuleList(\n",
       "      (0-1): 2 x Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (to_time): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (activation): GELU(approximate='none')\n",
       "    (diffusion_time_emb): DiffusionEmbedding(\n",
       "      (projection1): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (projection2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (diffusion): GaussianDiffusion(\n",
       "    (denoise_fn): DenoiseNet(\n",
       "      (time_emb): TrigonoTimeEmbedding(\n",
       "        (Wt): Linear(in_features=1, out_features=32, bias=False)\n",
       "      )\n",
       "      (h_emb): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (feed_forward): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (to_time): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (activation): GELU(approximate='none')\n",
       "      (diffusion_time_emb): DiffusionEmbedding(\n",
       "        (projection1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (projection2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (embedding_head): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=64, out_features=81, bias=True)\n",
       "  )\n",
       "  (embedding_predictor): EmbeddingPredictor(\n",
       "    (criterion): CrossEntropyLoss()\n",
       "    (embed_predictors): ModuleDict(\n",
       "      (channel_type): Linear(in_features=16, out_features=5, bias=True)\n",
       "      (currency): Linear(in_features=16, out_features=5, bias=True)\n",
       "      (mcc): Linear(in_features=16, out_features=100, bias=True)\n",
       "      (trx_category): Linear(in_features=16, out_features=12, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (numeric_projector): NumericalFeatureProjector(\n",
       "    (embed_predictors): ModuleDict(\n",
       "      (amount): Linear(in_features=16, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (mse_fn): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tppd.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled = tppd.generate(padded_batch=batch[0], lens=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['channel_type', 'currency', 'mcc', 'trx_category', 'amount', 'delta'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled['pred'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoise = DenoiseNet(embed_size=8, layer_num=2, diff_steps=100)\n",
    "x = torch.rand(32, 5, 1)\n",
    "t = torch.ones(32, 5).long()\n",
    "cond = torch.rand(32, 5, 8)\n",
    "\n",
    "diffusion = GaussianDiffusion(denoise_fn=denoise, diff_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "initial_state = torch.rand(32, 8)\n",
    "out = diffusion.sample((bs, 1), cond=initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/event_seq/experiments/rosbank/notebooks/tpp_ddpm.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f76765f6576656e74227d@ssh-remote%2Bmidas.skoltech.ru/home/event_seq/experiments/rosbank/notebooks/tpp_ddpm.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m out\u001b[39m.\u001b[39;49msize()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = None\n",
    "x_start = x.reshape(32*5, -1)\n",
    "noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "time = torch.randint(0, 100, (32*5,), device=x.device).long()\n",
    "\n",
    "x_noisy = diffusion.q_sample(x_start=x_start, t=time, noise=noise)\n",
    "x_recon = diffusion.denoise_fn(x_noisy, time, cond=cond.reshape(32*5, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([160, 1])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoise(x.reshape(32*5, -1), t.reshape(32*5, -1), cond.reshape(32*5, -1)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(174.6083, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusion.log_prob(x, cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = diffusion.sample((32, 5, 1), cond=torch.rand(32, 5, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(147.1917, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusion.log_prob(torch.rand(32, 5), cond=torch.rand(32, 5, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
