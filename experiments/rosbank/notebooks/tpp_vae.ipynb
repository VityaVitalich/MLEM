{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append('../../../')\n",
    "\n",
    "from configs.data_configs.rosbank import data_configs\n",
    "from configs.model_configs.gen.rosbank import model_configs\n",
    "from src.data_load.dataloader import create_data_loaders, create_test_loader\n",
    "\n",
    "from src.models.model_utils import NumericalFeatureProjector, EmbeddingPredictor\n",
    "import src.models.preprocessors as prp\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from einops import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_z(mean, logstd, k_iwae):\n",
    "    epsilon = torch.randn(k_iwae, mean.shape[0], mean.shape[1], mean.shape[2]).to(\n",
    "        logstd.device\n",
    "    )\n",
    "    z = epsilon * torch.exp(0.5 * logstd) + mean  # modified\n",
    "    z = z.view(-1, mean.shape[1], mean.shape[2])\n",
    "    return z\n",
    "\n",
    "\n",
    "def get_normal_kl(mean_1, log_std_1, mean_2=None, log_std_2=None):\n",
    "    \"\"\"\n",
    "    This function should return the value of KL(p1 || p2),\n",
    "    where p1 = Normal(mean_1, exp(log_std_1)), p2 = Normal(mean_2, exp(log_std_2) ** 2).\n",
    "    If mean_2 and log_std_2 are None values, we will use standard normal distribution.\n",
    "    Note that we consider the case of diagonal covariance matrix.\n",
    "    \"\"\"\n",
    "    if mean_2 is None:\n",
    "        mean_2 = torch.zeros_like(mean_1).to(mean_1.device)\n",
    "    if log_std_2 is None:\n",
    "        log_std_2 = torch.zeros_like(log_std_1).to(mean_1.device)\n",
    "    # ====\n",
    "    # https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians\n",
    "    # https://stats.stackexchange.com/questions/60680/kl-divergence-between-two-multivariate-gaussians\n",
    "\n",
    "    sigma_1 = torch.exp(log_std_1)\n",
    "    sigma_2 = torch.exp(log_std_2)\n",
    "\n",
    "    out = torch.log(sigma_2 / sigma_1)\n",
    "    out += (sigma_1**2 + (mean_1 - mean_2) ** 2) / (2 * (sigma_2**2))\n",
    "    out -= 1 / 2\n",
    "\n",
    "    return out\n",
    "\n",
    "class TPPVAE(nn.Module):\n",
    "\n",
    "    def __init__(self, model_conf, data_conf):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model_conf = model_conf\n",
    "        self.data_conf = data_conf\n",
    "\n",
    "        ### PROCESSORS ###\n",
    "        self.processor = prp.FeatureProcessor(\n",
    "            model_conf=model_conf, data_conf=data_conf\n",
    "        )\n",
    "        self.time_encoder = prp.TimeEncoder(\n",
    "            model_conf=self.model_conf, data_conf=self.data_conf\n",
    "        )\n",
    "\n",
    "        ### INPUT SIZE ###\n",
    "        all_emb_size = self.model_conf.features_emb_dim * len(\n",
    "            self.data_conf.features.embeddings\n",
    "        )\n",
    "\n",
    "        self.all_numeric_size = (\n",
    "            len(self.data_conf.features.numeric_values)\n",
    "            * self.model_conf.numeric_emb_size\n",
    "        )\n",
    "\n",
    "        self.input_dim = all_emb_size + self.all_numeric_size + self.model_conf.use_deltas\n",
    "        assert self.model_conf.time_embedding == 0\n",
    "        assert self.model_conf.use_deltas == True\n",
    "\n",
    "        self.history_encoder = nn.GRU(\n",
    "            input_size=self.input_dim,\n",
    "            hidden_size=self.model_conf.tppvae.hidden_rnn,\n",
    "            num_layers=self.model_conf.tppvae.num_layers_enc,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.h0 = nn.Parameter(torch.rand(self.model_conf.tppvae.hidden_rnn))\n",
    "        ### Encoder ###\n",
    "        self.net_joint = []\n",
    "        for i in range(self.model_conf.tppvae.joint_layer_num):\n",
    "            self.net_joint.append(nn.Linear(self.model_conf.tppvae.hidden_rnn, self.model_conf.tppvae.hidden_rnn))\n",
    "            self.net_joint.append(nn.GELU())\n",
    "        self.encoder_net_joint = nn.Sequential(*self.net_joint)\n",
    "\n",
    "        self.encoder_net_h = nn.Linear(self.model_conf.tppvae.hidden_rnn, self.model_conf.tppvae.hidden_rnn)\n",
    "        self.encoder_net_emb = nn.Linear(self.input_dim, self.model_conf.tppvae.hidden_rnn)\n",
    "        self.mu_head = nn.Linear(self.model_conf.tppvae.hidden_rnn, self.model_conf.tppvae.hidden_rnn)\n",
    "        self.logstd_head = nn.Linear(self.model_conf.tppvae.hidden_rnn, self.model_conf.tppvae.hidden_rnn)     \n",
    "\n",
    "\n",
    "        ### Decoder ###\n",
    "        self.net_joint = []\n",
    "        for i in range(self.model_conf.tppvae.joint_layer_num):\n",
    "            self.net_joint.append(nn.Linear(self.model_conf.tppvae.hidden_rnn, self.model_conf.tppvae.hidden_rnn))\n",
    "            self.net_joint.append(nn.GELU())\n",
    "        self.decoder_net_joint = nn.Sequential(*self.net_joint)\n",
    "        self.decoder_net_h = nn.Linear(self.model_conf.tppvae.hidden_rnn, self.model_conf.tppvae.hidden_rnn)\n",
    "        self.decoder_z_emb = nn.Linear(self.model_conf.tppvae.hidden_rnn, self.model_conf.tppvae.hidden_rnn)\n",
    "\n",
    "        # predict only next time\n",
    "        self.delta_head = nn.Linear(self.model_conf.tppvae.hidden_rnn, 1)\n",
    "        # predict embedding from history\n",
    "        self.embedding_head = nn.Sequential(\n",
    "            nn.Linear(self.model_conf.tppvae.hidden_rnn, self.model_conf.tppvae.hidden_rnn),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.model_conf.tppvae.hidden_rnn, self.input_dim)\n",
    "        )\n",
    "\n",
    "        # Predictors\n",
    "        self.embedding_predictor = EmbeddingPredictor(\n",
    "            model_conf=self.model_conf, data_conf=self.data_conf\n",
    "        )\n",
    "        self.numeric_projector = NumericalFeatureProjector(\n",
    "            model_conf=self.model_conf, data_conf=self.data_conf\n",
    "        )\n",
    "        self.mse_fn = torch.nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "    def numerical_loss(self, output):\n",
    "        # MSE\n",
    "        total_mse_loss = 0\n",
    "        for key, values in output[\"gt\"][\"input_batch\"].payload.items():\n",
    "            if key in self.processor.numeric_names:\n",
    "                gt_val = values.float()\n",
    "                pred_val = output[\"pred\"][key].squeeze(-1)\n",
    "\n",
    "                mse_loss = self.mse_fn(\n",
    "                    gt_val,\n",
    "                    pred_val,\n",
    "                )\n",
    "                mask = gt_val != 0\n",
    "                masked_mse = mse_loss * mask\n",
    "                total_mse_loss += (\n",
    "                    masked_mse.sum(dim=1)  # / (mask != 0).sum(dim=1)\n",
    "                ).mean()\n",
    "\n",
    "        return total_mse_loss\n",
    "\n",
    "    def delta_mse_loss(self, output):\n",
    "        # DELTA MSE\n",
    "        if self.model_conf.use_deltas:\n",
    "            gt_delta = output[\"gt\"][\"time_steps\"].diff(1)\n",
    "            if self.model_conf.use_log_delta:\n",
    "                gt_delta = torch.log(gt_delta + 1e-15)\n",
    "            delta_mse = self.mse_fn(gt_delta, output[\"pred\"][\"delta\"][:, :-1])\n",
    "            # print(delta_mse, gt_delta[0], output[\"gt\"][\"time_steps\"].diff(1)[0], output[\"gt\"][\"time_steps\"][0])\n",
    "            mask = output[\"gt\"][\"time_steps\"] != -1\n",
    "\n",
    "            delta_masked = delta_mse * mask[:, :-1]\n",
    "            delta_mse = delta_masked.sum() / (mask != 0).sum()\n",
    "        else:\n",
    "            delta_mse = torch.tensor(0)\n",
    "\n",
    "        return delta_mse\n",
    "\n",
    "\n",
    "    def loss(self, output, ground_truth):\n",
    "        \"\"\"\n",
    "        output: Dict that is outputed from forward method\n",
    "        \"\"\"\n",
    "        ### MSE ###\n",
    "        total_mse_loss = self.numerical_loss(output)\n",
    "        delta_mse_loss = self.delta_mse_loss(output)\n",
    "\n",
    "        ### CROSS ENTROPY ###\n",
    "        cross_entropy_losses = self.embedding_predictor.loss(\n",
    "            output[\"pred\"], output[\"gt\"][\"input_batch\"]\n",
    "        )\n",
    "        total_ce_loss = torch.sum(\n",
    "            torch.cat([value.unsqueeze(0) for _, value in cross_entropy_losses.items()])\n",
    "        )\n",
    "\n",
    "\n",
    "        losses_dict = {\n",
    "            \"total_mse_loss\": total_mse_loss,\n",
    "            \"total_CE_loss\": total_ce_loss,\n",
    "            \"delta_loss\": self.model_conf.delta_weight * delta_mse_loss,\n",
    "        }\n",
    "        losses_dict.update(cross_entropy_losses)\n",
    "\n",
    "        total_loss = (\n",
    "            self.model_conf.mse_weight * losses_dict[\"total_mse_loss\"]\n",
    "            + self.model_conf.CE_weight * total_ce_loss\n",
    "            + self.model_conf.delta_weight * delta_mse_loss\n",
    "            \n",
    "        )\n",
    "        losses_dict[\"total_loss\"] = total_loss\n",
    "\n",
    "        return losses_dict\n",
    "\n",
    "    def forward(self, padded_batch):\n",
    "        x, time_steps = self.processor(padded_batch)\n",
    "        x = self.time_encoder(x, time_steps)\n",
    "        \n",
    "        history_emb, mu, log_std = self.encode(x)\n",
    "        z = sample_z(mu, log_std, k_iwae=1)\n",
    "\n",
    "        pred = self.decode(z, history_emb)\n",
    "\n",
    "        gt = {\"input_batch\": padded_batch, \"time_steps\": time_steps}\n",
    "\n",
    "        res_dict = {\n",
    "            \"gt\": gt,\n",
    "            \"pred\": pred,\n",
    "            \"latent\": history_emb,\n",
    "        }\n",
    "        return res_dict\n",
    "    \n",
    "    def encode(self, x):\n",
    "        bs, seq_len, dim = x.size()\n",
    "        history_emb, _ = self.history_encoder(x)\n",
    "        history_emb = torch.cat([repeat(self.h0, \"D -> B L D\", B=bs, L=1), history_emb], dim=1)[:,:-1,:]\n",
    "\n",
    "        # use previous history embedding\n",
    "        out = self.encoder_net_joint(self.encoder_net_h(history_emb) + self.encoder_net_emb(x))\n",
    "\n",
    "        mu = self.mu_head(out)\n",
    "        log_std = self.logstd_head(out)\n",
    "\n",
    "        return history_emb, mu, log_std\n",
    "\n",
    "    def decode(self, z, h):\n",
    "        \n",
    "        # z is sampled but h goes from previous step\n",
    "        out = self.decoder_net_joint(self.decoder_net_h(h) + self.decoder_z_emb(z))\n",
    "        pred_delta = self.delta_head(out)\n",
    "        out = self.embedding_head(h)\n",
    "\n",
    "        pred = self.embedding_predictor(out)\n",
    "        pred.update(self.numeric_projector(out))\n",
    "        pred[\"delta\"] = pred_delta.squeeze(-1)\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def generate(self, bs, lens):\n",
    "        \n",
    "        initial_state = repeat(self.h0, \"D -> BS D\", BS=bs)\n",
    "        z = torch.randn(bs, self.model_conf.tppvae.hidden_rnn)\n",
    "        out = self.decoder_net_joint(self.decoder_net_h(initial_state) + self.decoder_z_emb(z))\n",
    "        pred_delta = self.delta_head(out).squeeze(-1)\n",
    "        out = self.embedding_head(initial_state)\n",
    "        out[:,-1] = pred_delta\n",
    "\n",
    "\n",
    "        gen_x = torch.zeros(bs, lens, self.input_dim)\n",
    "        gen_x[:,0,:] = out\n",
    "        for i in range(1, lens):\n",
    "            history_emb, _ = self.history_encoder(gen_x)\n",
    "            history_emb = history_emb[:,i-1,:]\n",
    "            z = torch.randn(bs, self.model_conf.tppvae.hidden_rnn)\n",
    "\n",
    "            out = self.decoder_net_joint(self.decoder_net_h(history_emb) + self.decoder_z_emb(z))\n",
    "            pred_delta = self.delta_head(out).squeeze(-1)\n",
    "            out = self.embedding_head(history_emb)\n",
    "            out[:, -1] = pred_delta\n",
    "            print(out.size())\n",
    "\n",
    "            gen_x[:,i,:] = out\n",
    "\n",
    "        pred = self.embedding_predictor(gen_x)\n",
    "        pred.update(self.numeric_projector(gen_x))\n",
    "        pred[\"delta\"] = gen_x[:,:,-1]\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_conf = data_configs()\n",
    "model_conf = model_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes: train 8467, val 946, test 0\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = create_data_loaders(data_conf, supervised=False)\n",
    "for batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = TPPVAE(model_conf=model_conf, data_conf=data_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = vae(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = vae.loss(out, batch[1])\n",
    "# loss['total_loss'].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 81])\n",
      "torch.Size([5, 81])\n",
      "torch.Size([5, 81])\n",
      "torch.Size([5, 81])\n",
      "torch.Size([5, 81])\n",
      "torch.Size([5, 81])\n",
      "torch.Size([5, 81])\n",
      "torch.Size([5, 81])\n",
      "torch.Size([5, 81])\n",
      "torch.Size([5, 81])\n"
     ]
    }
   ],
   "source": [
    "res = vae.generate(5, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0897, 0.0660, 0.0782, 0.0555, 0.0766, 0.0608, 0.0942, 0.0701, 0.1118,\n",
       "         0.0619, 0.1044],\n",
       "        [0.0319, 0.0731, 0.0640, 0.1137, 0.0410, 0.0667, 0.0715, 0.1088, 0.0749,\n",
       "         0.0929, 0.0550],\n",
       "        [0.0857, 0.0426, 0.0798, 0.0813, 0.0729, 0.0770, 0.0721, 0.0355, 0.0761,\n",
       "         0.0698, 0.0608],\n",
       "        [0.0722, 0.0852, 0.0849, 0.0505, 0.1164, 0.0882, 0.1076, 0.0697, 0.0637,\n",
       "         0.0741, 0.0729],\n",
       "        [0.0624, 0.0869, 0.0674, 0.1015, 0.0788, 0.0450, 0.0894, 0.0633, 0.0482,\n",
       "         0.0500, 0.0572]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['delta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
