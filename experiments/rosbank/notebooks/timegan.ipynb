{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/event_seq/experiments/rosbank/notebooks/../../../src/trainers/base_trainer.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pyarrow.parquet as pq\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../../../')\n",
    "\n",
    "from configs.data_configs.rosbank import data_configs\n",
    "from configs.model_configs.gen.rosbank import model_configs\n",
    "from src.models.mTAND.model import MegaNet, MegaNetCE, MegaNetSupervised\n",
    "from src.data_load.dataloader import create_data_loaders, create_test_loader\n",
    "from src.trainers.trainer_mTAND import MtandTrainer\n",
    "\n",
    "from src.create_embeddings import create_embeddings\n",
    "\n",
    "from src.data_load import split_strategy\n",
    "from src.data_load.data_utils import prepare_data\n",
    "from src.data_load.splitting_dataset import (\n",
    "    ConvertingTrxDataset,\n",
    "    TargetDataset,\n",
    "    DropoutTrxDataset,\n",
    "    SplittingDataset,\n",
    "    TargetEnumeratorDataset,\n",
    ")\n",
    "from src.data_load.dataloader import collate_splitted_rows, padded_collate, PaddedBatch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from src.models.preprocessors import FeatureProcessor\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from src.models.gen_models import SeqGen\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3, 5, 7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros([5,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_generator(batch_size, z_dim, T_mb, max_seq_len):\n",
    "  \"\"\"Random vector generation.\n",
    "  \n",
    "  Args:\n",
    "    - batch_size: size of the random vector\n",
    "    - z_dim: dimension of random vector\n",
    "    - T_mb: time information for the random vector\n",
    "    - max_seq_len: maximum sequence length\n",
    "    \n",
    "  Returns:\n",
    "    - Z_mb: generated random vector\n",
    "  \"\"\"\n",
    "  Z_mb = list()\n",
    "  for i in range(batch_size):\n",
    "    temp = np.zeros([max_seq_len, z_dim])\n",
    "    temp_Z = np.random.uniform(0., 1, [T_mb[i], z_dim])\n",
    "    temp[:T_mb[i],:] = temp_Z\n",
    "    Z_mb.append(temp)\n",
    "  return torch.tensor(np.stack(Z_mb))\n",
    "\n",
    "class D(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init___()\n",
    "        self.rnn = nn.GRU(input_size = 9, hidden_size=9, batch_first=True)\n",
    "\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(9, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "class TG(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.GRU(input_size=7, hidden_size=9, batch_first=True)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(9, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(9, 7)\n",
    "        )\n",
    "        self.generator = nn.GRU(input_size=7, hidden_size=9, batch_first=True)\n",
    "    def forward(self, x):\n",
    "        latens, hn = self.encoder(x)\n",
    "        decoded = self.decoder(latens)\n",
    "\n",
    "        bs, l, d = x.size()\n",
    "        Z = random_generator(bs, d, [l]*bs, l)\n",
    "        gen_latens = self.generator(Z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = random_generator(3, 7, [4, 4, 5], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4727, 0.5375, 0.2085, 0.6701, 0.7857, 0.2511, 0.1718],\n",
       "         [0.8589, 0.6937, 0.2587, 0.0881, 0.2629, 0.5737, 0.6829],\n",
       "         [0.3491, 0.2518, 0.7863, 0.1141, 0.9193, 0.1637, 0.7340],\n",
       "         [0.3878, 0.6488, 0.8230, 0.9885, 0.6167, 0.3225, 0.7368],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.9500, 0.6378, 0.7989, 0.4544, 0.9919, 0.5176, 0.1610],\n",
       "         [0.7488, 0.2407, 0.7099, 0.4868, 0.9233, 0.1697, 0.4151],\n",
       "         [0.2066, 0.9919, 0.8938, 0.0862, 0.2189, 0.6643, 0.1941],\n",
       "         [0.2517, 0.4732, 0.5657, 0.8848, 0.4648, 0.2628, 0.5808],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.5084, 0.1570, 0.9775, 0.2200, 0.4831, 0.9544, 0.8391],\n",
       "         [0.3010, 0.2247, 0.8673, 0.8620, 0.8760, 0.5144, 0.0328],\n",
       "         [0.2851, 0.3758, 0.5251, 0.4691, 0.4919, 0.1496, 0.7183],\n",
       "         [0.1576, 0.8898, 0.9043, 0.8255, 0.0421, 0.8710, 0.9014],\n",
       "         [0.9034, 0.3027, 0.1185, 0.2005, 0.0529, 0.8897, 0.3866]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
