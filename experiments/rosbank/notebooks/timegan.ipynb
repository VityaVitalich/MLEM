{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/event_seq/experiments/rosbank/notebooks/../../../src/trainers/base_trainer.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pyarrow.parquet as pq\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../../../')\n",
    "\n",
    "from configs.data_configs.rosbank import data_configs\n",
    "from configs.model_configs.gen.rosbank import model_configs\n",
    "from src.models.mTAND.model import MegaNet, MegaNetCE, MegaNetSupervised\n",
    "from src.data_load.dataloader import create_data_loaders, create_test_loader\n",
    "from src.trainers.trainer_mTAND import MtandTrainer\n",
    "\n",
    "from src.create_embeddings import create_embeddings\n",
    "\n",
    "from src.data_load import split_strategy\n",
    "from src.data_load.data_utils import prepare_data\n",
    "from src.data_load.splitting_dataset import (\n",
    "    ConvertingTrxDataset,\n",
    "    TargetDataset,\n",
    "    DropoutTrxDataset,\n",
    "    SplittingDataset,\n",
    "    TargetEnumeratorDataset,\n",
    ")\n",
    "from src.data_load.dataloader import collate_splitted_rows, padded_collate, PaddedBatch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from src.models.preprocessors import FeatureProcessor\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from src.models.gen_models import SeqGen\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_generator(batch_size, z_dim, T_mb, max_seq_len):\n",
    "  \"\"\"Random vector generation.\n",
    "  \n",
    "  Args:\n",
    "    - batch_size: size of the random vector\n",
    "    - z_dim: dimension of random vector\n",
    "    - T_mb: time information for the random vector\n",
    "    - max_seq_len: maximum sequence length\n",
    "    \n",
    "  Returns:\n",
    "    - Z_mb: generated random vector\n",
    "  \"\"\"\n",
    "  Z_mb = list()\n",
    "  for i in range(batch_size):\n",
    "    temp = np.zeros([max_seq_len, z_dim])\n",
    "    temp_Z = np.random.uniform(0., 1, [T_mb[i], z_dim])\n",
    "    temp[:T_mb[i],:] = temp_Z\n",
    "    Z_mb.append(temp)\n",
    "  return torch.tensor(np.stack(Z_mb)).float()\n",
    "\n",
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('Norm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find(\"GRU\") != -1:\n",
    "      for name,param in m.named_parameters():\n",
    "        if 'weight_ih' in name:\n",
    "          init.xavier_uniform_(param.data)\n",
    "        elif 'weight_hh' in name:\n",
    "          init.orthogonal_(param.data)\n",
    "        elif 'bias' in name:\n",
    "          param.data.fill_(0)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"Embedding network between original feature space to latent space.\n",
    "\n",
    "        Args:\n",
    "          - input: input time-series features. (L, N, X) = (24, ?, 6)\n",
    "          - h3: (num_layers, N, H). [3, ?, 24]\n",
    "\n",
    "        Returns:\n",
    "          - H: embeddings\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_rnn, num_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.gru = GRU(input_size=input_size, hidden_size=hidden_rnn, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_rnn, hidden_rnn)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        # в оригинале стремная инициализация весов\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def forward(self, x, sigmoid=True):\n",
    "        e_outputs, _ = self.rnn(input)\n",
    "        H = self.fc(e_outputs)\n",
    "        if sigmoid:\n",
    "            H = self.sigmoid(H)\n",
    "        return H\n",
    "\n",
    "class Recovery(nn.Module):\n",
    "    \"\"\"Recovery network from latent space to original space.\n",
    "\n",
    "    Args:\n",
    "      - H: latent representation\n",
    "      - T: input time information\n",
    "\n",
    "    Returns:\n",
    "      - X_tilde: recovered data\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_rnn, num_layers):\n",
    "        super(Recovery, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size=hidden_rnn, hidden_size=input_size, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(input_size, input_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def forward(self, input, sigmoid=True):\n",
    "        r_outputs, _ = self.rnn(input)\n",
    "        X_tilde = self.fc(r_outputs)\n",
    "        if sigmoid:\n",
    "            X_tilde = self.sigmoid(X_tilde)\n",
    "        return X_tilde\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator function: Generate time-series data in latent space.\n",
    "\n",
    "    Args:\n",
    "      - Z: random variables\n",
    "      - T: input time information\n",
    "\n",
    "    Returns:\n",
    "      - E: generated embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_rnn, num_layers):\n",
    "        super(Generator, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size=hidden_rnn, hidden_size=input_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(input_size, input_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def forward(self, input, sigmoid=True):\n",
    "        g_outputs, _ = self.rnn(input)\n",
    "        E = self.fc(g_outputs)\n",
    "        if sigmoid:\n",
    "            E = self.sigmoid(E)\n",
    "        return E\n",
    "\n",
    "\n",
    "class Supervisor(nn.Module):\n",
    "    \"\"\"Generate next sequence using the previous sequence.\n",
    "\n",
    "    Args:\n",
    "      - H: latent representation\n",
    "      - T: input time information\n",
    "\n",
    "    Returns:\n",
    "      - S: generated sequence based on the latent representations generated by the generator\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_rnn, num_layers):\n",
    "        super(Supervisor, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size=hidden_rnn, hidden_size=hidden_rnn, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(input_size, input_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def forward(self, input, sigmoid=True):\n",
    "        s_outputs, _ = self.rnn(input)\n",
    "        S = self.fc(s_outputs)\n",
    "        if sigmoid:\n",
    "            S = self.sigmoid(S)\n",
    "        return S\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminate the original and synthetic time-series data.\n",
    "\n",
    "    Args:\n",
    "      - H: latent representation\n",
    "      - T: input time information\n",
    "\n",
    "    Returns:\n",
    "      - Y_hat: classification results between original and synthetic time-series\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_rnn, num_layers):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size=hidden_rnn, hidden_size=hidden_rnn, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(input_size, 1)\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def forward(self, input):\n",
    "        d_outputs, _ = self.rnn(input)\n",
    "        Y_hat = self.fc(d_outputs)\n",
    "        return Y_hat\n",
    "\n",
    "\n",
    "class TG(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(input_suze, hidden_rnn, num_layers)\n",
    "        self.encoder = Encoder(input_size=input_size, hidden_rnn=hidden_rnn, num_layers=num_layers)\n",
    "        self.decoder = Recovery(input_size=input_size, hidden_rnn=hidden_rnn, num_layers=num_layers)\n",
    "        self.supervisor = Supervisor(hidden_rnn=hidden_rnn, num_layers=num_layers)\n",
    "        self.generator = Generator(input_size=input_size, hidden_rnn=hidden_rnn, num_layers=num_layers)\n",
    "        self.discriminator = Discriminator(hidden_rnn=hidden_rnn, num_layers=num_layers)\n",
    "\n",
    "    def train_embedder(self, x):\n",
    "        latens = self.encoder(x)\n",
    "        decoded = self.decoder(latens)\n",
    "\n",
    "        mse = F.mse_loss(latens, x, reduction='none').sum(dim=[1,2]).mean()\n",
    "        \n",
    "        return mse\n",
    "\n",
    "    def train_generator(self, x):\n",
    "        bs, l, d = x.size()\n",
    "        Z = random_generator(bs, d, [l]*bs, l)\n",
    "        gen_latens = self.supervisor(self.generator(Z))\n",
    "        latens = self.encoder(x)\n",
    "\n",
    "        mse = F.mse_loss(latens, x, reduction='none').sum(dim=[1,2]).mean()\n",
    "        return mse\n",
    "\n",
    "    def train_joint(self, x):\n",
    "\n",
    "    def train_discriminator(self, x):\n",
    "\n",
    "        \n",
    "    def generate(self, bs, d, lens, max_len):\n",
    "        Z = random_generator(bs, d, lens, l)\n",
    "        gen_latens, hn = self.generator(Z)\n",
    "        return gen_latens\n",
    "    \n",
    "    def discriminate(self, gen_latens):\n",
    "        d_scores = self.d(gen_latens)\n",
    "        return d_scores\n",
    "\n",
    "    def discriminator_loss(self, gen_latens):\n",
    "        scores = self.discriminate(gen_latens)\n",
    "        return scores.sum(dim=[1]).mean()\n",
    "    \n",
    "    def generation_loss(self, x, gen_latens):\n",
    "        return F.mse_loss(x, recon_x, reduction='none').sum(dim=[1,2]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3, 5, 7) \n",
    "net = TG()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5, 7]), torch.Size([3, 5, 7]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_scores, gen_latens, decoded, x1 = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.1805, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.mse_loss(x1, decoded, reduction='none').sum(dim=[1,2]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
