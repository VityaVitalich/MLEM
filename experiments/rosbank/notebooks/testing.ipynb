{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pyarrow.parquet as pq\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "sys.path.append('../../../')\n",
    "from configs.data_configs.rosbank import data_configs\n",
    "from configs.model_configs.mTAN.rosbank import model_configs\n",
    "from src.data_load.dataloader import create_data_loaders\n",
    "from src.models.mTAND.model import MegaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = data_configs()\n",
    "model_conf = model_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cl_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>event_time</th>\n",
       "      <th>mcc</th>\n",
       "      <th>channel_type</th>\n",
       "      <th>currency</th>\n",
       "      <th>trx_category</th>\n",
       "      <th>trx_count</th>\n",
       "      <th>target_target_flag</th>\n",
       "      <th>target_target_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10018</td>\n",
       "      <td>[10.609081944147828, 10.596659732783579, 10.81...</td>\n",
       "      <td>[17120.38773148148, 17133.667800925927, 17134....</td>\n",
       "      <td>[13, 2, 13, 2, 1, 18, 13, 2, 13, 2, 5, 13, 9, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[5, 3, 5, 3, 1, 1, 5, 3, 5, 3, 1, 5, 5, 5, 5]</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10030</td>\n",
       "      <td>[4.61512051684126, 6.90875477931522, 10.598857...</td>\n",
       "      <td>[17141.0, 17141.0, 17145.0, 17147.0, 17147.0, ...</td>\n",
       "      <td>[9, 9, 21, 1, 25, 6, 14, 14, 3, 3, 3, 13, 1, 3...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 1, 1, 3, ...</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>59.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10038</td>\n",
       "      <td>[7.4127640174265625, 7.370230641807081, 7.8180...</td>\n",
       "      <td>[17301.0, 17301.0, 17301.0, 17301.774780092594...</td>\n",
       "      <td>[1, 1, 1, 2, 2, 4, 2, 8, 1, 22, 8, 1, 8, 4, 2,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 2, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, ...</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10057</td>\n",
       "      <td>[7.494708263135679, 7.736394428979239, 10.7789...</td>\n",
       "      <td>[17151.0, 17151.0, 17153.0, 17154.0, 17155.0, ...</td>\n",
       "      <td>[6, 21, 2, 6, 2, 4, 2, 22, 15, 2, 1, 35, 4, 2,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 4, 1, 4, 1, 3, 1, 1, 3, 1, 1, 1, 4, 1, ...</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>62961.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10062</td>\n",
       "      <td>[8.31898612539206, 8.824824939175638, 6.509067...</td>\n",
       "      <td>[17143.0, 17143.0, 17143.0, 17144.0, 17144.0, ...</td>\n",
       "      <td>[80, 15, 37, 38, 11, 11, 2, 24, 7, 5, 5, 11, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>107126.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cl_id                                             amount  \\\n",
       "0  10018  [10.609081944147828, 10.596659732783579, 10.81...   \n",
       "1  10030  [4.61512051684126, 6.90875477931522, 10.598857...   \n",
       "2  10038  [7.4127640174265625, 7.370230641807081, 7.8180...   \n",
       "3  10057  [7.494708263135679, 7.736394428979239, 10.7789...   \n",
       "4  10062  [8.31898612539206, 8.824824939175638, 6.509067...   \n",
       "\n",
       "                                          event_time  \\\n",
       "0  [17120.38773148148, 17133.667800925927, 17134....   \n",
       "1  [17141.0, 17141.0, 17145.0, 17147.0, 17147.0, ...   \n",
       "2  [17301.0, 17301.0, 17301.0, 17301.774780092594...   \n",
       "3  [17151.0, 17151.0, 17153.0, 17154.0, 17155.0, ...   \n",
       "4  [17143.0, 17143.0, 17143.0, 17144.0, 17144.0, ...   \n",
       "\n",
       "                                                 mcc  \\\n",
       "0  [13, 2, 13, 2, 1, 18, 13, 2, 13, 2, 5, 13, 9, ...   \n",
       "1  [9, 9, 21, 1, 25, 6, 14, 14, 3, 3, 3, 13, 1, 3...   \n",
       "2  [1, 1, 1, 2, 2, 4, 2, 8, 1, 22, 8, 1, 8, 4, 2,...   \n",
       "3  [6, 21, 2, 6, 2, 4, 2, 22, 15, 2, 1, 35, 4, 2,...   \n",
       "4  [80, 15, 37, 38, 11, 11, 2, 24, 7, 5, 5, 11, 1...   \n",
       "\n",
       "                                        channel_type  \\\n",
       "0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                            currency  \\\n",
       "0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                        trx_category  trx_count  \\\n",
       "0      [5, 3, 5, 3, 1, 1, 5, 3, 5, 3, 1, 5, 5, 5, 5]         15   \n",
       "1  [5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 1, 1, 3, ...         42   \n",
       "2  [1, 1, 1, 2, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, ...        111   \n",
       "3  [1, 1, 4, 1, 4, 1, 3, 1, 1, 3, 1, 1, 1, 4, 1, ...         61   \n",
       "4  [1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, ...         82   \n",
       "\n",
       "  target_target_flag target_target_sum  \n",
       "0                  0               0.0  \n",
       "1                  1             59.51  \n",
       "2                  0               0.0  \n",
       "3                  1          62961.31  \n",
       "4                  1         107126.35  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(conf.train_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9717it [00:01, 8952.58it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader = create_data_loaders(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MegaNet(model_conf=model_conf, data_conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['decoder_output', 'z', 'time_steps'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 100, 65]), torch.Size([20, 64, 2]), torch.Size([20, 100]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['decoder_output'].size(), out['z'].size(), out['time_steps'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_z(mean, logvar, model_conf):\n",
    "    epsilon = torch.randn(model_conf.k_iwae, mean.shape[0], mean.shape[1], mean.shape[2])\n",
    "    z = epsilon * torch.exp(.5 * logvar) + mean # same as in mTAN\n",
    "    z = z.view(-1, mean.shape[1], mean.shape[2])\n",
    "    return z\n",
    "\n",
    "qz_mean, qz_logvar = torch.split(out, 2, dim=-1)\n",
    "z = sample_z(qz_mean, qz_logvar, model_conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 64, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class multiTimeAttention(nn.Module):\n",
    "    def __init__(self, input_dim, nhidden=16, embed_time=16, num_heads=1):\n",
    "        super(multiTimeAttention, self).__init__()\n",
    "        assert embed_time % num_heads == 0\n",
    "        self.embed_time = embed_time\n",
    "        self.embed_time_k = embed_time // num_heads\n",
    "        self.h = num_heads\n",
    "        self.dim = input_dim\n",
    "        self.nhidden = nhidden\n",
    "        self.linears = nn.ModuleList(\n",
    "            [\n",
    "                nn.Linear(embed_time, embed_time),\n",
    "                nn.Linear(embed_time, embed_time),\n",
    "                nn.Linear(input_dim * num_heads, nhidden),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def attention(self, query, key, value, mask=None, dropout=None):\n",
    "        \"Compute 'Scaled Dot Product Attention'\"\n",
    "        dim = value.size(-1)\n",
    "        d_k = query.size(-1)\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        scores = scores.unsqueeze(-1).repeat_interleave(dim, dim=-1)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask.unsqueeze(-3) == 0, -1e9)\n",
    "        p_attn = F.softmax(scores, dim=-2)\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    "        return torch.sum(p_attn * value.unsqueeze(-3), -2), p_attn\n",
    "\n",
    "    def forward(self, query, key, value, mask=None, dropout=None):\n",
    "        \"Compute 'Scaled Dot Product Attention'\"\n",
    "        batch, seq_len, dim = value.size()\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        value = value.unsqueeze(1)\n",
    "\n",
    "        query, key = [\n",
    "            linear(x).view(x.size(0), -1, self.h, self.embed_time_k).transpose(1, 2)\n",
    "            for linear, x in (zip(self.linears, (query, key)))\n",
    "        ]\n",
    "        x, _ = self.attention(query, key, value, mask, dropout)\n",
    "        x = x.transpose(1, 2).contiguous().view(batch, -1, self.h * dim)\n",
    "\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "\n",
    "class dec_mtan_rnn(nn.Module):\n",
    " \n",
    "    def __init__(self, input_dim, query, latent_dim=2, nhidden=16, \n",
    "                 embed_time=16, num_heads=1, learn_emb=False, device='cuda'):\n",
    "        super(dec_mtan_rnn, self).__init__()\n",
    "        self.embed_time = embed_time\n",
    "        self.dim = input_dim\n",
    "        self.device = device\n",
    "        self.nhidden = nhidden\n",
    "        self.query = query\n",
    "        self.learn_emb = learn_emb\n",
    "        self.att = multiTimeAttention(2*nhidden, 2*nhidden, embed_time, num_heads)\n",
    "        self.gru_rnn = nn.GRU(latent_dim, nhidden, bidirectional=True, batch_first=True)    \n",
    "        self.z0_to_obs = nn.Sequential(\n",
    "            nn.Linear(2*nhidden, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, input_dim))\n",
    "        if learn_emb:\n",
    "            self.periodic = nn.Linear(1, embed_time-1)\n",
    "            self.linear = nn.Linear(1, 1)\n",
    "        \n",
    "        \n",
    "    def learn_time_embedding(self, tt):\n",
    "        tt = tt.to(self.device)\n",
    "        tt = tt.unsqueeze(-1)\n",
    "        out2 = torch.sin(self.periodic(tt))\n",
    "        out1 = self.linear(tt)\n",
    "        return torch.cat([out1, out2], -1)\n",
    "        \n",
    "        \n",
    "    def fixed_time_embedding(self, pos):\n",
    "        d_model = self.embed_time\n",
    "        pe = torch.zeros(pos.shape[0], pos.shape[1], d_model)\n",
    "        position = 48.*pos.unsqueeze(2)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(np.log(10.0) / d_model))\n",
    "        pe[:, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, :, 1::2] = torch.cos(position * div_term)\n",
    "        return pe\n",
    "       \n",
    "    def forward(self, z, time_steps):\n",
    "        out, _ = self.gru_rnn(z)\n",
    "        time_steps = time_steps.cpu()\n",
    "        if self.learn_emb:\n",
    "            query = self.learn_time_embedding(time_steps).to(self.device)\n",
    "            key = self.learn_time_embedding(self.query.unsqueeze(0)).to(self.device)\n",
    "        else:\n",
    "            query = self.fixed_time_embedding(time_steps).to(self.device)\n",
    "            key = self.fixed_time_embedding(self.query.unsqueeze(0)).to(self.device)\n",
    "        out = self.att(query, key, out)\n",
    "        out = self.z0_to_obs(out)\n",
    "        return out        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = dec_mtan_rnn(33, torch.linspace(0., 1., 64), latent_dim=2, nhidden=32, \n",
    "                 embed_time=16, num_heads=2, learn_emb=True, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = decoder(z, batch[0].payload['event_time'].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 100, 33])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 64, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 64, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z0.view(-1, qz0_mean.shape[1], qz0_mean.shape[2]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiTimeAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, nhidden=16, \n",
    "                 embed_time=16, num_heads=1):\n",
    "        super(multiTimeAttention, self).__init__()\n",
    "        assert embed_time % num_heads == 0\n",
    "        self.embed_time = embed_time\n",
    "        self.embed_time_k = embed_time // num_heads\n",
    "        self.h = num_heads\n",
    "        self.dim = input_dim\n",
    "        self.nhidden = nhidden\n",
    "        self.linears = nn.ModuleList([nn.Linear(embed_time, embed_time), \n",
    "                                      nn.Linear(embed_time, embed_time),\n",
    "                                      nn.Linear(input_dim*num_heads, nhidden)])\n",
    "        \n",
    "    def attention(self, query, key, value, mask=None, dropout=None):\n",
    "        \"Compute 'Scaled Dot Product Attention'\"\n",
    "        dim = value.size(-1)\n",
    "        d_k = query.size(-1)\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "                 / math.sqrt(d_k)\n",
    "        scores = scores.unsqueeze(-1).repeat_interleave(dim, dim=-1)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask.unsqueeze(-3) == 0, -1e9)\n",
    "        p_attn = F.softmax(scores, dim = -2)\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    "        return torch.sum(p_attn*value.unsqueeze(-3), -2), p_attn\n",
    "    \n",
    "    \n",
    "    def forward(self, query, key, value, mask=None, dropout=None):\n",
    "        \"Compute 'Scaled Dot Product Attention'\"\n",
    "        batch, seq_len, dim = value.size()\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        value = value.unsqueeze(1)\n",
    "        \n",
    "        query, key = [l(x).view(x.size(0), -1, self.h, self.embed_time_k).transpose(1, 2)\n",
    "                      for l, x in tqdm(zip(self.linears, (query, key)))]\n",
    "        x, _ = self.attention(query, key, value, mask, dropout)\n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(batch, -1, self.h * dim)\n",
    "\n",
    "        print(x.size())\n",
    "        print(self.linears)\n",
    "        print(self.linears[-1].weight.size())\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "class enc_mtan_rnn(nn.Module):\n",
    "    def __init__(self, input_dim, query, latent_dim=2, nhidden=16, \n",
    "                 embed_time=16, num_heads=1, learn_emb=False, device='cuda'):\n",
    "        super(enc_mtan_rnn, self).__init__()\n",
    "        self.embed_time = embed_time\n",
    "        self.dim = input_dim\n",
    "        self.device = device\n",
    "        self.nhidden = nhidden\n",
    "        self.query = query\n",
    "        self.learn_emb = learn_emb\n",
    "        self.att = multiTimeAttention(input_dim, nhidden, embed_time, num_heads)\n",
    "        self.gru_rnn = nn.GRU(nhidden, nhidden, bidirectional=True, batch_first=True)\n",
    "        self.hiddens_to_z0 = nn.Sequential(\n",
    "            nn.Linear(2*nhidden, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, latent_dim * 2))\n",
    "        if learn_emb:\n",
    "            self.periodic = nn.Linear(1, embed_time-1)\n",
    "            self.linear = nn.Linear(1, 1)\n",
    "        \n",
    "    \n",
    "    def learn_time_embedding(self, tt):\n",
    "        tt = tt.to(self.device)\n",
    "        tt = tt.unsqueeze(-1)\n",
    "        out2 = torch.sin(self.periodic(tt))\n",
    "        out1 = self.linear(tt)\n",
    "        return torch.cat([out1, out2], -1)\n",
    "    \n",
    "    def fixed_time_embedding(self, pos):\n",
    "        d_model=self.embed_time\n",
    "        pe = torch.zeros(pos.shape[0], pos.shape[1], d_model)\n",
    "        position = 48.*pos.unsqueeze(2)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(np.log(10.0) / d_model))\n",
    "        pe[:, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, :, 1::2] = torch.cos(position * div_term)\n",
    "        return pe\n",
    "       \n",
    "    def forward(self, x, time_steps):\n",
    "        time_steps = time_steps.cpu()\n",
    "        mask = x[:, :, self.dim:]\n",
    "        mask = torch.cat((mask, mask), 2)\n",
    "        if self.learn_emb:\n",
    "            key = self.learn_time_embedding(time_steps).to(self.device)\n",
    "            query = self.learn_time_embedding(self.query.unsqueeze(0)).to(self.device)\n",
    "        else:\n",
    "            key = self.fixed_time_embedding(time_steps).to(self.device)\n",
    "            query = self.fixed_time_embedding(self.query.unsqueeze(0)).to(self.device)\n",
    "        out = self.att(query, key, x, mask=None)\n",
    "        out, _ = self.gru_rnn(out)\n",
    "        out = self.hiddens_to_z0(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_points = torch.linspace(0, 1., 5)\n",
    "\n",
    "\n",
    "am = features.payload['amount']\n",
    "mcc = features.payload['mcc']\n",
    "\n",
    "emb1 = nn.Embedding(384, 16)\n",
    "mcce = emb1(mcc)\n",
    "\n",
    "am = am.unsqueeze(-1)\n",
    "x = torch.cat([mcce, am], dim=-1)\n",
    "\n",
    "time_steps = features.payload['event_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x.size(-1)\n",
    "query = ref_points\n",
    "\n",
    "\n",
    "enc = enc_mtan_rnn(input_dim, query, latent_dim=2, nhidden=16, \n",
    "                 embed_time=16, num_heads=2, learn_emb=True, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 1668.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 5, 34])\n",
      "ModuleList(\n",
      "  (0-1): 2 x Linear(in_features=16, out_features=16, bias=True)\n",
      "  (2): Linear(in_features=34, out_features=16, bias=True)\n",
      ")\n",
      "torch.Size([16, 34])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out = enc(x.float(), time_steps.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0151,  0.0093, -0.0105,  0.0625], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureProcessor(nn.Module):\n",
    "\n",
    "    def __init__(self, model_conf, data_conf):\n",
    "        super(FeatureProcessor, self).__init__()\n",
    "        self.model_conf = model_conf\n",
    "        self.data_conf = data_conf\n",
    "\n",
    "        self.emb_names = list(self.data_conf.features.embeddings.keys())\n",
    "        self.init_embed_layers()\n",
    "\n",
    "    def init_embed_layers(self):\n",
    "        self.embed_layers = nn.ModuleDict()\n",
    "        \n",
    "        for name in self.emb_names:\n",
    "            vocab_size = self.data_conf.features.embeddings[name]['max_value']\n",
    "            self.embed_layers[name] = nn.Embedding(vocab_size, self.model_conf.features_emb_dim)\n",
    "\n",
    "    def forward(self, padded_batch):\n",
    "        numeric_values = []\n",
    "\n",
    "        for key, values in padded_batch.payload.items():\n",
    "            if key in self.emb_names:\n",
    "                numeric_values.append(self.embed_layers[key](values))\n",
    "            else:\n",
    "                if key == 'event_time':\n",
    "                    time_steps = values\n",
    "                else:\n",
    "                    numeric_values.append(values.unsqueeze(-1).float())\n",
    "        \n",
    "        x = torch.cat(numeric_values, dim=-1)\n",
    "        return x, time_steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = FeatureProcessor(model_conf=model_conf, data_conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = processor(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 100, 65])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MegaEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, model_conf, data_conf):\n",
    "        super(MegaEncoder, self).__init__()\n",
    "        self.model_conf = model_conf\n",
    "        self.data_conf = data_conf\n",
    "\n",
    "        all_emb_size = self.model_conf.features_emb_dim * len(self.data_conf.features.embeddings)\n",
    "        all_numeric_size = len(self.data_conf.features.numeric_values)\n",
    "        self.input_dim = all_emb_size + all_numeric_size\n",
    "\n",
    "        self.preprocessor = FeatureProcessor(model_conf=self.model_conf, data_conf=self.data_conf)\n",
    "\n",
    "        self.ref_points = torch.linspace(0., 1., self.model_conf.num_ref_points)\n",
    "        self.encoder = enc_mtan_rnn(\n",
    "                        self.input_dim,\n",
    "                        self.ref_points,\n",
    "                        latent_dim=self.model_conf.latent_dim,\n",
    "                        nhidden=self.model_conf.ref_point_dim, \n",
    "                        embed_time=self.model_conf.time_emb_dim,\n",
    "                        num_heads=self.model_conf.num_heads_enc,\n",
    "                        learn_emb=True,\n",
    "                        device=self.model_conf.device)\n",
    "\n",
    "    def forward(self, padded_batch):\n",
    "        x, time_steps = self.preprocessor(padded_batch)\n",
    "        out = self.encoder(x, time_steps.float())\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = MegaEncoder(model_conf=model_conf, data_conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.data_load.dataloader.PaddedBatch at 0x7fed44502440>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 1010.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 64, 130])\n",
      "ModuleList(\n",
      "  (0-1): 2 x Linear(in_features=16, out_features=16, bias=True)\n",
      "  (2): Linear(in_features=130, out_features=16, bias=True)\n",
      ")\n",
      "torch.Size([16, 130])\n"
     ]
    }
   ],
   "source": [
    "out = enc(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 64, 4])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def learn_time_embedding(tt):\n",
    "    tt = tt.unsqueeze(-1)\n",
    "    out2 = torch.sin(periodic(tt))\n",
    "    out1 = linear(tt)\n",
    "    return torch.cat([out1, out2], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_points = torch.linspace(0, 1., 5)\n",
    "periodic = nn.Linear(1, 16-1)\n",
    "linear = nn.Linear(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = learn_time_embedding(time_steps.float())\n",
    "query = learn_time_embedding(ref_points.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 100, 16]), torch.Size([1, 5, 16]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key.size(), query.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiTimeAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, nhidden=16, \n",
    "                 embed_time=16, num_heads=1):\n",
    "        super(multiTimeAttention, self).__init__()\n",
    "        assert embed_time % num_heads == 0\n",
    "        self.embed_time = embed_time\n",
    "        self.embed_time_k = embed_time // num_heads\n",
    "        self.h = num_heads\n",
    "        self.dim = input_dim\n",
    "        self.nhidden = nhidden\n",
    "        self.linears = nn.ModuleList([nn.Linear(embed_time, embed_time), \n",
    "                                      nn.Linear(embed_time, embed_time),\n",
    "                                      nn.Linear(input_dim*num_heads, nhidden)])\n",
    "        \n",
    "    def attention(self, query, key, value, mask=None, dropout=None):\n",
    "        \"Compute 'Scaled Dot Product Attention'\"\n",
    "        dim = value.size(-1)\n",
    "        d_k = query.size(-1)\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "                 / math.sqrt(d_k)\n",
    "        scores = scores.unsqueeze(-1).repeat_interleave(dim, dim=-1)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask.unsqueeze(-3) == 0, -1e9)\n",
    "        p_attn = F.softmax(scores, dim = -2)\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    "        return torch.sum(p_attn*value.unsqueeze(-3), -2), p_attn\n",
    "    \n",
    "    \n",
    "    def forward(self, query, key, value, mask=None, dropout=None):\n",
    "        \"Compute 'Scaled Dot Product Attention'\"\n",
    "        batch, seq_len, dim = value.size()\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        value = value.unsqueeze(1)\n",
    "        \n",
    "        query, key = [l(x).view(x.size(0), -1, self.h, self.embed_time_k).transpose(1, 2)\n",
    "                      for l, x in tqdm(zip(self.linears, (query, key)))]\n",
    "        x, _ = self.attention(query, key, value, mask, dropout)\n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(batch, -1, self.h * dim)\n",
    "\n",
    "        print(x.size())\n",
    "        print(self.linears)\n",
    "        print(self.linears[-1].weight.size())\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = multiTimeAttention(dim, 16, 16, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 2166.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 5, 34])\n",
      "ModuleList(\n",
      "  (0-1): 2 x Linear(in_features=16, out_features=16, bias=True)\n",
      "  (2): Linear(in_features=34, out_features=16, bias=True)\n",
      ")\n",
      "torch.Size([16, 34])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out = att(query, key, x.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 5, 16])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "audio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
